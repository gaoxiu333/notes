# LLM 提示词 Cheat Sheet 🚀

## 基本概念
- **提示词（Prompt）**: 你提供给模型的指令或问题，可以包括上下文、输入示例等，以获得更精准的结果。
- **提示工程（Prompt Engineering）**: 设计有效的提示以指导模型更好地完成任务的方法。

## 📌 提示词 4 要素
| **要素** | **作用** | **示例** |
|----------|----------|-----------|
| **指令** | 说明任务 | `"请将文本分类为'中性'、'否定'或'肯定'。"` |
| **上下文** | 提供背景信息 | `"你是一名情感分析专家。"` |
| **输入数据** | 需要处理的内容 | `"文本：这顿饭很棒！"` |
| **输出指示** | 设定格式/限制范围 | `"仅返回情绪类别，不要额外解释。"` |

## 📌 提示词示例
### ✅ 最佳示例（完整）
```text
你是一名情感分析专家。请将以下文本分类为"中性"、"否定"或"肯定"。
请仅返回情绪类别，不要额外解释。
文本：这顿饭很棒！
情绪：
```
**可能输出**: 肯定

## 📌 提示优化技巧
✅ **清晰具体**：明确指令，避免歧义  
✅ **提供上下文**：复杂任务时，给予背景信息  
✅ **格式化输入**：结构化数据，减少误解  
✅ **设定输出格式**：控制答案长度 & 形式

🎯 **结论**：**指令 + 上下文 + 输入数据 + 输出指示 = 更好的结果！** 🚀

## 📌 设计原则
✅ **清晰具体**：直接说明任务，避免模糊表述  
✅ **格式规范**：使用分隔符（如 ###），限制字数、格式  
✅ **示例引导**：提供示例，优化输出

## 📌 提示优化示例

### 1️⃣ 直接指令，避免歧义
❌ 不佳示例：
```text
解释提示工程的概念，保持简短。
```
✅ 更好示例：
```text
用 2-3 句话向高中生解释提示工程的概念。
```

### 2️⃣ 明确格式，减少错误
❌ 不佳示例：
```text
提取文本中的地名。
```
✅ 更好示例：
```text
提取以下文本中的地名，格式：
地点：<逗号分隔的地名列表>
```

### 3️⃣ 关注"要做什么"，而非"不要做什么"
❌ 不佳示例：
```text
不要询问兴趣，不要问个人信息。
```
✅ 更好示例：
```text
推荐全球热门电影，不询问兴趣或个人信息。
```

## 📌 常见任务类型

### 1. 文本概括
- **关键句提取**：`用一句话解释...`
- **精简内容**：`总结上文，保留核心信息`

### 2. 信息提取
- **显式提问**：`段落中的XX是什么？`

### 3. 问答
- **结构化模板**：
```text
根据下文回答问题，答案简短。不确定则回答"未知"。
上下文：[文本]
问题：[问题]
答案：
```
- **限制格式**：`答案不超过10字`

### 4. 对话系统
- **角色设定**：`你是一个[科学家助手]，用通俗语言解释`
- **风格控制**：`回答需小学生能理解`
- **连续性维护**：保留历史对话上下文

### 5. 推理任务
- **分步解法**：步骤1: 找出所有奇数 → 步骤2: 求和 → 步骤3: 判断奇偶性
- **数学提示**：`逐步计算并验证每一步结果`
- **错误检查**：要求展示中间过程

## 通用技巧
- **符号强化**：用`"""`包裹文本/`>`引导示例
- **格式控制**：要求`用逗号分隔列表`/`避免专业术语`
- **测试迭代**：对复杂任务多次尝试不同提示词

# 零样本提示

如今，经过大量数据训练并调整指令的LLM能够执行零样本任务。我们在前一节中尝试了一些零样本示例。以下是我们使用的一个示例：

_提示：_

```
将文本分类为中性、负面或正面。文本：我认为这次假期还可以。情感：
```

_输出：_

```
中性
```

当零样本不起作用时，建议在提示中提供演示或示例，这就引出了少样本提示。在下一节中，我们将演示少样本提示。
# 少样本提示
少样本提示可以作为一种技术，以启用上下文学习，我们在提示中提供演示以引导模型实现更好的性能。
模型通过提供一个示例（即1-shot）已经学会了如何执行任务。对于更困难的任务，我们可以尝试增加演示（例如3-shot、5-shot、10-shot等）。
_提示：_

```
“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是：我们在非洲旅行时看到了这些非常可爱的whatpus。“farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是：
```

_输出：_

```
当我们赢得比赛时，我们都开始庆祝跳跃。
```
任务类型涉及几个更多的推理步骤。换句话说，如果我们将问题分解成步骤并向模型演示，这可能会有所帮助。最近，[思维链（CoT）提示(opens in a new tab)](https://arxiv.org/abs/2201.11903)已经流行起来，以解决更复杂的算术、常识和符号推理任务
## 链式思考（CoT）提示[](https://www.promptingguide.ai/zh/techniques/cot#%E9%93%BE%E5%BC%8F%E6%80%9D%E8%80%83cot%E6%8F%90%E7%A4%BA)
CoT 和 少样本集合
```
这组数中的奇数加起来是偶数：4、8、9、15、12、2、1。A：将所有奇数相加（9、15、1）得到25。答案为False。这组数中的奇数加起来是偶数：15、32、5、13、82、7、1。A：
```
两样本 CoT(结合`让我们逐步思考`)
```
我去市场买了10个苹果。我给了邻居2个苹果和修理工2个苹果。然后我去买了5个苹果并吃了1个。我还剩下多少苹果？让我们逐步思考。
```
## 自我一致性
可以提供一系列示例，展示如何逐步推理解决类似问题。这些示例帮助模型理解问题的结构和解决方法，从而在面对新的问题时，能够生成更准确和一致的答案
##  生成知识提示
生成知识以作为提示的一部分，类似于让大模型从常理中推理出答案。
## 链式提示
将任务分解为许多子任务。 确定子任务后，将子任务的提示词提供给语言模型，得到的结果作为新的提示词的一部分。 这就是所谓的链式提示（prompt chaining），一个任务被分解为多个子任务，根据子任务创建一系列提示操作。
## 思维树（ToT）
```
假设三位不同的专家来回答这个问题。
所有专家都写下他们思考这个问题的第一个步骤，然后与大家分享。
然后，所有专家都写下他们思考的下一个步骤并分享。
以此类推，直到所有专家写完他们思考的所有步骤。
只要大家发现有专家的步骤出错了，就让这位专家离开。
请问...
```
# 检索增强生成 (RAG)
完成这类知识密集型的任务，有助于缓解“幻觉”问题
## # 方向性刺激提示
生成你想要的摘要信息
# ReAct 框架

## 参考
https://arxiv.org/abs/2205.11916
这篇论文的概括还不错
https://www.promptingguide.ai/zh/techniques/ape
自动提示词，下边还有很多参考