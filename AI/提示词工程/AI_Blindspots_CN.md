LLM中的盲点：AI编程实践观察(Sonnet系列模型为重点)。未来可能会针对这些问题提出Cursor规则建议。

## 三法则原则(Rule of Three)

_2025-03-13_

软件工程中的"三法则"指出：你可以容忍代码重复一次，但当第三次出现时就应该进行重构。这是对DRY(Don't Repeat Yourself)原则的细化，因为有时消除重复的方式并不明显，等到第三次出现时解决方案往往会更清晰。(参见[错误的抽象](https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction))

LLM特别容易产生重复代码。如果没有特别提示，当你要求LLM修改程序时，它会直接输出一个包含修改的新程序副本。要让LLM主动决定重构代码消除重复，需要它特意花精力进行清理工作。(实际上Sonnet 3.7也有这种倾向，但如果你查看Claude Code的系统提示，会发现他们特意指示模型不要过度主动，因为模型容易偏离当前任务)更糟的是，如果代码已经在代码库中被到处复制粘贴，LLM会认为你希望继续这种模式。必须明确要求模型减少重复。

### 示例

- 我让LLM为某些功能编写测试，结果测试间出现了大量重复逻辑。必须明确要求它提取辅助方法。(另一个难点：当LLM编写新测试时，它需要知道辅助方法才能使用。在代理模式下，你只能希望它能查看正确的文件找到辅助方法！)

## 文化吞噬战略(Culture Eats Strategy)

_2025-03-12_

"文化吞噬战略"指出：无论战略多么完美，如果团队文化无法执行，战略就会失败。如果问题是执行层面的，应该改变文化而非制定更复杂的战略。

默认情况下，LLM存在于"潜在空间"的特定区域：生成代码时会基于其微调方式和当前上下文窗口(包括系统提示和已读入上下文的文件)产生特定风格。这种风格会自我强化：如果上下文中大量使用某个库，LLM会继续使用；反之如果库未被提及且LLM未经过相关微调，它就不会使用(虽然有例外，但这基本描述了Sonnet 3.7的行为模式)。

如果LLM持续产生你不满意的结果，你需要改变它的"文化"：将其置于潜在空间的不同区域。可以通过修改Cursor规则(调整提示词)，也可以重构现有代码使其符合你期望的风格，因为LLM的训练目标就是预测上下文中的下一个token。微调、提示词和代码库共同构成了"文化"：微调无法改变，而代码库比提示词影响更大。

### 示例

- Sonnet 3.7的默认风格是偏好同步而非异步Python。要让其可靠地编写异步代码，必须强制它将代码库中大部分现有代码改为异步。

## 认知局限(Know Your Limits)

_2025-03-12_

了解自身局限和工具边界很重要，这样才能在必要时寻求帮助。

Sonnet 3.7不太擅长认识自身局限。要让它告知无法完成的任务，至少需要明确提示(例如Sonnet的系统提示会指示其在被问及非常小众的话题时明确警告用户可能存在幻觉)。特别在代理模式下，只让LLM做它确实能完成的事情非常重要。

### 示例

- Sonnet 3.7深信自己能够执行shell命令。在代理编程模式下如果没有bash命令可用，当它决定需要使文件可执行时，会在文件系统中创建随机shell脚本来尝试完成目标。常见情况是Sonnet说"我要做X"，却生成完全不同的Y工具调用。最佳解决方案是改进提示词(不完美，Sonnet会忘记)或直接提供能完成目标的专用工具(专用工具能防止Sonnet尝试通用bash调用)。

## 狗摇尾巴(The tail wagging the dog)

_2025-03-10_

"狗摇尾巴"指次要事物控制主要事物的现象。软件工程中常见原因是过于专注解决某个底层问题而忘记编写代码的初衷。

LLM特别容易出现这个问题。最常见的问题是聊天模式下，LLM的所有操作都会被放入上下文。虽然LLM有一定能力区分重要性，但如果放入太多无关内容，它会越来越难记住应该做什么。良好的初始提示和上下文管理会有帮助。Claude Code的聪明之处在于可以让子代理在专用上下文窗口中完成任务，而不会污染全局上下文。

### 示例

- 如果没有仔细提示，当你让LLM思考如何做某事时，它经常会忘记只是要求思考，而直接尝试去做那件事。

## 科学调试(Scientific Debugging)

_2025-03-09_

遇到bug时有两种修复方式：一种是随机尝试碰运气，另一种是系统性地检查假设与现实的差异。长期来看科学调试方法更好，即使耗时更长，也能让你对代码库有更好理解。

非推理模型不会使用科学方法。它会"猜测"修复方案并尝试一次性解决。在代理循环中，它可以重新运行测试套件查看是否成功(但更可能陷入死亡循环)。

业界普遍建议使用推理模型进行调试(实际上人们更喜欢使用Grok 3或DeepSeek-R1等模型解决这类问题)。就我个人而言，在AI编程时仍会保持对代码工作方式的详细心智模型，所以自己找出根本原因也很合理(不一定要自己修复，如果你告诉模型问题所在，它通常能做对)。

### 示例

- 代理模式LLM最可怕的死亡循环之一是尝试修复环境配置问题，例如某个包缺失。Sonnet 3.7有个有趣的问题：它默认认为`pip`可用，但在`uv`创建的默认venv中不可用，它无法理解问题所在，只会浪费大量token随机尝试。

## 记忆碎片(Memento)

_2025-03-07_

就像电影《记忆碎片》中主角无法形成新记忆一样，你使用的LLM也没有记忆。每次要求它执行任务时，它都必须重建足够上下文。这些上下文包括提示(如项目的Cursor规则)、显式/隐式附加的上下文，以及代理模式下模型决定请求的内容。仅此而已！你的模型每次开始新聊天时都在快速重新理解代码库。

"令人惊叹的不是熊跳得好，而是熊居然会跳舞。"LLM每次请求都能从零开始重新理解代码库的能力确实惊人。但这很脆弱：如果模型未能将正确文件放入上下文，它可能很快开始错误理解你的意图。

帮助模型做正确的事：确保有文档可供参考，并确保模型能找到这些文档(通过提示或放在模型预期位置)。避免在没有说明如何与项目整体配合的情况下要求重大更改(目标不一致更容易造成危害)。

### 示例

- 我让Sonnet 3.7为已有项目制定端到端测试方案。Sonnet理解为整个代码库的存在理由就是测试，并重写README只讨论测试。

## 遵守规范(Respect the Spec)

_2025-03-07_

设计变更时，重要的是清楚系统哪些部分可以改变，哪些不能。例如：
- 公开API应尽量避免破坏性变更
- 与外部系统交互时必须符合实际API
- 测试失败时不应删除测试而应理解测试是否正确

共同点是系统某些部分是规范的一部分，虽然偶尔确实需要修改规范，但日常编码应该遵守规范。

LLM不太擅长遵守规范。它们会愉快地删除测试、更改API，编码时做任何事。有些边界是常识可能编码到提示中，但有些只有LLM想出新的奖励函数破解方法时才会发现。审查LLM生成代码的最重要功能之一就是确保它没有以不协调的方式改变规范。

### 示例

- Sonnet无法修复测试时，将测试内容替换为`assert True`
- 尝试使文件类型良好时，一个公共函数返回带有`pass`键的字典，Sonnet 3.7尝试使用TypedDict类语法，但因pass是保留关键字而失败。作为"修复"，Sonnet决定将键重命名为`pass_`，这显然行不通。

## 使用MCP服务器(Use MCP Servers)

_2025-03-06_

模型上下文协议(MCP)服务器为LLM与环境交互提供标准接口。Cursor代理模式和Claude Code广泛使用代理。例如，不再需要单独的RAG系统来查找和提供相关上下文文件，LLM可以调用MCP查找所需文件后再决定操作。类似地，模型可以运行测试或构建后立即修复问题。显然Anthropic内置的MCP服务器很有用，应该尽可能使用代理模式。

认知状态说明：以下部分为理论探讨，尚未实践。

进一步问题是是否应该编写自己的MCP服务器。内置MCP服务器之一就是shell，所以实践中可以在Cursor开启YOLO模式并在Cursor规则中添加指令说明运行哪些命令，这确实相当有效。但非常危险！任意shell命令可以做任何事，LLM预训练数据中有大量会破坏环境的命令。所以你基本上只能祈祷LLM某天不会失控(或者你足够谨慎审核每个命令——说实话谁有这时间)。

替代方案是编写MCP服务器暴露你希望模型访问的命令(注意这与大多数人编写MCP访问现有平台API的思路不同)。原则上这应该更容易控制实际调用的工具，但截至2025年3月Cursor对此支持很差。特别是无法按项目配置不同MCP服务器，且生态系统发展方向是提供通用工具而非项目特定的`npm run`式MCP服务器。

### 示例

- 让Sonnet 3.7类型检查TypeScript项目并修复错误时，代理模式会使用MCP运行命令、获取输出并决定后续操作。这比手动复制粘贴终端输出到聊天窗口方便得多。必须适当提示(通过Cursor规则或MCP)，因为LLM容易幻觉应该运行的命令。例如我的项目中默认会幻觉出`npm run typecheck`，但实际上不工作。

## 使用静态类型(Use Static Types)

_2025-03-06_

动态与静态类型系统的永恒争论在于原型设计便捷性与长期维护性的权衡。LLM的兴起大大降低了对原型友好语言的需求，因为LLM可以处理样板代码和重构。相应地应该选择静态类型。你会希望建立代理配置让LLM在修改后获知类型错误，这样重构时能轻松知道需要更新哪些文件。注意token成本。

不幸的是训练语料高度偏向Python和JavaScript。它们的类型系统可用，但都是渐进式类型系统，需要严格配置类型检查器设置(或仔细提示LLM正确配置)。

理论上Rust应该是LLM的良好目标语言。但实际上LLM生成Rust代码的能力不如Python/JavaScript。

## 行走骨架(Walking Skeleton)

_2025-03-06_

[行走骨架](https://wiki.c2.com/?WalkingSkeleton)是指包含所有必要部分的最简陋端到端系统实现。重点是先让端到端系统工作，再改进各个部分。我仍记得斯坦福博士生时期[Jacob Steinhardt](https://jsteinhardt.stat.berkeley.edu/)告诉我这个技巧，至今难忘。

在LLM编程时代，让整个系统工作变得前所未有的简单。通过使用系统，下一步该做什么会变得很明显。尽快达到这个阶段。LLM无法自行试用它编写的代码！

## 阅读文档(Read the Docs)

_2025-03-04_

学习新框架或库时，简单使用可以通过复制粘贴教程代码并调整完成。但某些时候最好完整阅读文档，全面了解软件的能与不能。

AI编程的一大优势是LLM从预训练中知道很多内容。对于预训练集中突出的流行框架，LLM可能已记住大部分使用方法。但对于不太常见或超出知识截止日期的内容，很可能会得到幻觉结果。理想情况下代理模型应该知道进行网络搜索找到所需文档。然而Sonnet目前不支持网络搜索，所以需要手动提供文档页面。幸运的是Cursor使这非常方便：只需在聊天信息中放入URL就会包含其内容。

### 示例

- 尝试用LLM编写调用Python函数进行评估的YAML配置时，模型最初幻觉了连接方式。提供手册作为上下文后，模型理解了如何修复错误并更新函数输出格式以符合文档指导。

## 保持文件精简(Keep Files Small)

_2025-03-04_

代码文件应该多大一直有争议。有人认为应该基于单一职责原则(一个类一个文件)，也有人认为大文件在特定情况下可以接受。

不要创建过大的文件，如果你的RAG系统只能按文件提供上下文，会耗尽上下文；而且像Cursor这样的IDE会开始无法应用LLM创建的补丁(即使成功，应用补丁也可能耗时很长——例如Cursor 0.45.17上对64KB文件应用55处编辑就很耗时)。达到128KB时，很难让Sonnet 3.7修改整个文件(Sonnet上下文窗口只有20万token)。

也没有理由不保持文件精简；LLM可以处理拆分文件后正确导入的所有繁琐工作。

### 示例

- 让Cursor中的Sonnet 3.7将小型测试类从471KB的Python文件移到另一个文件。虽然单个编辑很小，但Sonnet 3.7没有提出Cursor补丁程序能很好应用的编辑。

## 使用自动化代码格式化(Use Automatic Code Formatting)

_2025-03-04_

像gofmt、rustfmt和black这样的自动化代码格式化工具帮助在代码库中实施一致的编码风格。LLM通常不太擅长遵循机械规则，如"空行不应该有尾随空格"或"确保行宽78字符"。应该使用合适的工具完成这类工作。

这也适用于lint修复：优先选择能自动修复的lint，不要浪费LLM能力让它修复；把LLM留给困难问题。

## 需求而非解决方案(Requirements, not Solutions)

_2025-03-03_

人类软件工程中，确定做什么时的常见反模式是直接提出解决方案，而不先明确所有需求。通常一旦写下所有需求，解决方案就唯一确定了；没有需求时，很容易陷入对特定解决方案的无意义争论。

LLM对你的需求一无所知。当你没有指定所有约束就让它做事时，它会用训练集中最可能的答案填补所有空白。有时这没问题。但如果你需要更定制化的方案，就必须明确告诉LLM。如果你提出的要求过于模糊导致LLM误解，最好编辑原始提示重试；因为之前的对话会留在上下文中，错误的解释会让LLM更难进入符合你需求的潜在空间区域。

另外，如果你确定解决方案某些方面应该以特定方式工作，告诉LLM会很有帮助，因为这也能帮助进入正确的潜在空间区域。但必须确保你是正确的，因为LLM会非常努力地按照你的要求做，即使不恰当。

### 示例

- 让Sonnet创建可视化时，它可能会生成SVG。但如果指定需要交互性，它会给出React应用。一个关键词导致巨大差异！

## 无状态工具(Stateless Tools)

_2025-03-03_

你的工具应该是无状态的：每次调用都独立，调用间不应存在需要维护的状态。不幸的是shell作为非常流行的工具，有一种特别有害的本地状态：当前工作目录。Sonnet 3.7非常不擅长跟踪当前工作目录。应该努力设置项目使所有命令都能从单一目录运行。

理想情况下，模型应该被调优为倾向于不使用改变状态的工具命令，即使这些命令可用。如果状态绝对必要，持续向模型提供当前状态可能有助于提高一致性。角色扮演社区可能有很多相关经验。

### 示例

- 一个TypeScript项目分为三个子组件：common、backend和frontend。每个组件都是自己的NPM模块。从项目根目录运行的Cursor必须cd到相应组件目录运行测试命令，并会混淆当前工作目录。更好的方式是打开特定组件作为工作空间并在那里工作。

## 预备性重构(Preparatory Refactoring)

_2025-03-03_

[预备性重构](https://martinfowler.com/articles/preparatory-refactoring-example.html)指出应该先重构使变更容易，再进行变更。重构可能很复杂，但因为保持语义不变，比变更本身更容易评估。

当前LLM如果没有计划说明应该先重构，不会这样分解变更。它们会尝试一次性完成所有工作。它们有时也像过度热心的初级工程师，把童子军原则看得太重，在变更时清理无关内容。审查LLM变更很重要，为使审查容易，所有重构应该提前作为独立变更提出。

理想情况下，应该指示LLM不做无关重构(注意：根据经验Cursor Sonnet 3.7不太擅长遵循指令，所以效果不如预期)。或者，在LLM预期修改的代码上进行预扫描，让它有机会在实际变更前做想做的重构。有时指示模型遵循良好实践(如添加显式类型注解)的上下文可能使问题更糟，因为模型确实被指示添加注解。准确确定LLM应该编辑的代码范围也有帮助。

### 示例

- 我指示LLM修复由于我在文件中的本地修改导致的导入错误，但在修复导入后，它还为文件中一些未注解的lambda添加了类型注解。雪上加霜的是，它错误地注解了其中一个，导致代理循环螺旋。

## 黑盒测试(Black Box Testing)

_2025-03-03_

黑盒测试指出应该在不知道组件内部结构的情况下测试其功能。默认情况下LLM很难遵守这点，因为默认实现文件会被放入上下文，或者代理被调优为查看实现来理解如何交互。Cursor中的Sonnet 3.7还有强烈的使代码一致的倾向，即使黑盒测试建议保持冗余以避免实现中的bug直接反映到测试中，它也会尝试消除测试文件中的冗余。

理想情况下，当文件被加载到上下文时应该能够屏蔽或总结实现，避免过度拟合应该隐藏的内部实现细节。需要架构师指定信息隐藏边界。

### 示例

- 我让Cursor中的Sonnet 3.7修复失败的测试。它做了必要修复，但也更新了硬编码的预期常量，改为使用与原文件相同的算法计算，而不是保持测试最初编写的常量。另见[预备性重构](https://ezyang.github.io/ai-blindspots/preparatory-refactoring/)。

## 停止挖掘(Stop Digging)

_2025-03-03_

除了非常战术性的情况外，当前模型不知道陷入困境时应该停止挖掘。假设你想实现功能X。开始工作后中途发现应该先做Y。人类知道应该中止先去实现Y；LLM会继续挖掘，忠实地尝试完成原始任务。某种意义上这是可取的，因为当LLM按要求而非它认为你实际想要的内容工作时，你有更多控制权。

通常最好一开始就避免这种情况。例如很流行的做法是用推理模型制定计划喂给编码模型。规划阶段可以避免让编码模型做需要更多准备的不明智工作。其次，像Sonnet这样的代理LLM会主动将文件加载到上下文，阅读它们并基于看到的内容进行规划。所以LLM可能无需你告诉就发现需要做的事情。

理想情况下，模型应该能够意识到"出了问题"并向用户询问。因为这需要宝贵上下文，可能最好通过单独的看门狗LLM来检测。

### 示例

- 修改蒙特卡洛模拟的随机数采样方式后，让Claude Code修复所有测试，其中一些是对精确随机采样策略的快照。但新实现在测试时是非确定性的，所以测试会根据采样随机通过/失败。Claude Code无法注意到测试在通过/失败间切换，在尝试强制测试通过失败后，开始大幅放宽测试条件以适应非确定性，而不是建议重构模拟使其确定性采样。
