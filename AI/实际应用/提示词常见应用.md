# 提示工程作为开发者学科

> 译自 [Prompt Engineering as a Developer Discipline](https://neon.tech/blog/prompt-engineering-developer-discipline)  
> 作者：Andrew Tate  
> 发布：2025/04/21

## Few-Shot 和 One-Shot 提示：展示，而不仅仅是说明

当你给出所需输出的示例时，可以大大提高得到格式正确、语义贴合的代码的概率。这种方法充分利用了语言模型的**模式匹配能力**。

**没有示例时：**

> 写一个函数，计算斐波那契数列。

**提供示例后：**

```txt
写一个计算斐波那契数列的函数。
示例函数风格如下：
----
def is_prime(n: int) -> bool:
    """
    判断一个数字是否为质数。

    参数:
        n: 要检查的数字

    返回:
        True 如果n是质数, 否则False
    """
    if n <= 1:
        return False
    ...

----
```

**总结：**  
提供示例后，模型不仅模仿了你的注释风格，还遵循了你的函数签名规范，生成了更符合你项目习惯的代码。

---

## Chain-of-Thought（思维链）：诱导逐步推理

让 AI**逐步推理**，可以让逻辑更清晰，减少潜在错误。这在复杂算法或业务逻辑中尤其重要。

**没有推理过程时：**

> 写一个快速排序（quicksort）算法。

**要求逐步推理后：**

```txt
写一个快速排序函数。请先解释算法和时间复杂度，再列出实现步骤，再写代码，并加上异常处理与详细注释。
请：
- 首先解释 quicksort 算法及其时间复杂度
- 然后概述实施中所需的关键组件
- 使用清晰、描述性的变量名称编写函数
- 添加适当的错误处理
- 包括解释每个主要步骤的注释

```

**总结：**  
引导 AI 先推理，再编码，可以显著提高代码质量和可读性。

---

## Self-Consistency（自洽性）：多路径推理并择优

对于复杂问题，要求模型**生成多个不同方案**，然后进行比较和推荐，可以提高最终答案的可靠性。

**传统做法：**

> 编写代码以检测链表中的周期。

输出：

使用弗洛伊德快慢指针算法。

**改进做法：**

```txt
生成三种不同的方法来检测链表中的循环。对于每种方法：
- 解释算法的逻辑
- 分析其时间复杂度和空间复杂度
- 在代码中实现该方法
- 然后，比较这三种方法，并推荐在存在潜在内存限制的生产环境中应优先使用哪种方法。
```

**总结：**  
要求多方案探索，让模型在给出答案前自己进行权衡，模拟了资深开发者的思考流程。

---

## Skeleton Prompting（骨架提示）：结构化填空式控制

如果需要**精确控制生成内容的结构**，可以提供代码骨架，要求模型在指定位置补充内容。

**无结构时：**

> 写一个用户信息展示的 React 组件。

**有骨架时：**

```txt
const UserProfile = ({ userId }) => {

  // TODO: 添加用于存储用户数据、加载状态和错误信息的state

  // TODO: 添加useEffect，用于根据userId异步获取用户数据

  // TODO: 添加加载状态下的JSX渲染

  // TODO: 添加错误状态下的JSX渲染

  // TODO: 添加用于展示用户信息的渲染方法

  // TODO: 根据需要添加辅助方法（Helper Methods）

}
要求使用TypeScript类型，并遵循React Hooks的最佳实践。
```

**总结：**  
骨架提示消除了模型的结构猜测，让输出更符合预期。

---

## Output Schemas（输出模式）与 Format Directives（格式指令）

当生成内容需要与其他系统集成时，提前定义**输出格式**非常重要。

**无结构时：**

> 写一个函数，返回某地的天气数据。

返回的是描述性文本。

**定义输出模式后：**

> 生成天气数据函数，要求返回 JSON 格式，包括位置、当前天气、未来预报。

输出：

- 严格按照指定的 JSON 结构
- 易于系统直接解析和使用

**总结：**  
明确的输出规范，能显著减少后期清洗和兼容性问题。

---

## Configuration Parameters（配置参数）：像调整运行时设置一样调节提示

模型参数（如 temperature, top_p, max_tokens）不仅影响风格，更**重塑输出行为**。

| Temperature | 行为特点                 | 最佳应用场景           |
| ----------- | ------------------------ | ---------------------- |
| 0.0         | 完全确定性输出           | 生产环境代码、SQL 查询 |
| 0.1 - 0.4   | 基本确定，略有变化       | 文档生成、注释撰写     |
| 0.5 - 0.7   | 平衡创造力与确定性       | 设计模式、架构建议     |
| 0.8 - 1.0   | 较强创造性               | UI/UX 创意、替代实现   |
| > 1.0       | 非常具有创造性，可能失控 | 脑暴、不拘一格的思路   |

同一个斐波那契函数，在不同温度下生成的实现方式可能大相径庭。

---

## Prompt Anatomy（提示解剖学）：像定义接口一样组织输入

每个有效的提示（Prompt）通常由可识别的几个部分组成 —— **角色（Persona）**、**任务（Task）**、**上下文（Context）**、**输出格式（Output Structure）和示例（Examples）**。

将提示分解为这些组件，可以提高清晰度，并使其更易于进行版本控制、文档编写和重用。

这实际上构成了**你与模型之间的接口层**。

一个结构良好的提示可以进一步细分为以下各个部分：

- **角色（Persona）**：你希望 AI 模拟的角色或专业水平
- **任务（Task）**：你所请求的具体动作或输出内容
- **上下文（Context）**：提供背景信息或施加的约束条件
- **输出格式（Output Structure）**：规定响应的格式和组织方式
- **示例（Examples）**：期望输出的示范样例（用于 Few-Shot 学习）

采用**组件化**的系统，可以让你在预定义的模块之间灵活组合，而无需每次都从零开始撰写提示。

---

# **元件库示例（Component Library Example）**

以下展示了一个**基于组件的提示系统**在实际应用中的可能结构：

```js
// 角色（Personas）
const personas = {
  backendExpert: `你是一位拥有15年以上经验的资深后端开发工程师，
                  专注于分布式系统和API设计。你在所有代码中都优先考虑
                  可扩展性、安全性和可维护性。`,

  securitySpecialist: `你是一名网络安全专家，深谙应用安全、威胁建模、
                       以及安全编码实践。你总能识别代码中的潜在漏洞。`,
};

// 输出格式（Output Formats）
const formats = {
  json: `将你的响应以有效的JSON对象返回，不要附加任何解释。`,

  markdown: `将你的响应格式化为Markdown，
             包括适当的标题、带有语言标签的代码块，以及必要时使用项目符号列表。`,
};

// 任务模板（Task Templates）
const tasks = {
  codeReview: `审查以下代码中的{aspect}问题：
               
               \`\`\`{language}
               {code}
               \`\`\`
               
               请特别关注{focus_area}。`,

  implementation: `编写{language}代码，实现{feature}，并满足以下要求：
                   
                   {requirements}`,
};

// 组合完整提示（Composing a complete prompt）
function createPrompt(components) {
  return [components.persona, components.task, components.format].join("\n\n");
}

// 使用示例（Usage）
const securityReviewPrompt = createPrompt({
  persona: personas.securitySpecialist,
  task: tasks.codeReview
    .replace("{aspect}", "安全")
    .replace("{language}", "python")
    .replace("{code}", userCode)
    .replace("{focus_area}", "输入验证和SQL注入风险"),
  format: formats.markdown,
});
```

这种**基于组件**的方法带来了以下几个优点：

- **一致性（Consistency）**：标准化的组件确保整个应用中的输出风格统一
- **可维护性（Maintainability）**：只需更新一次组件，所有引用它的提示都会同步更新
- **版本控制（Version Control）**：可以像管理普通代码一样跟踪提示组件的变更历史
- **协作性（Collaboration）**：团队成员可以跨项目共享并重用提示组件
- **测试性（Testing）**：可以单独验证各个提示组件的可靠性和效果
- **文档性（Documentation）**：提示架构自带清晰文档属性，便于理解和维护

---

## Prompt Linting（提示检查）：执行前的自动质量验证

就像代码要用 lint 工具检测一样，Prompt 在发送到 LLM 前也应该经过自动验证。

提示（Prompts）容易受到以下几类结构性问题的影响：

- **说明不明确（Ambiguous instructions）**：指令可以被多种方式理解
- **冲突的约束（Conflicting constraints）**：存在互相矛盾的要求
- **缺少格式指令（Missing format directives）**：对输出结构的期望不清晰
- **遗忘的变量（Forgotten variables）**：模板占位符未被正确替换
- **示例不足（Insufficient examples）**：Few-shot 模式中缺少足够案例
- **角色不明确（Unclear personas）**：模型的角色设定描述模糊

**LLM 驱动的自填充检查（LLM-Powered Self-Linting）**

通过 ，要求模型给出：
目前**Meta-Prompt**最强大的一种方法是使用 LLM（大型语言模型）本身作为**linting 工具**。

这种“元使用”（Meta-use of AI）充分利用了模型自身对**语言和推理的理解能力**，以识别潜在问题。

示例代码如下：

```js
// 基于LLM的提示自检（LLM-based prompt self-linting）
async function selfLintPrompt(prompt, model) {
  const metaPrompt = `
    你是一名提示工程（Prompt Engineering）专家，任务是分析并改进提示内容。
    
    请根据以下标准审查提示：
    1. 指令的清晰度
    2. 潜在的歧义
    3. 结构性问题
    4. 缺失的约束或格式规范
    5. 要求的一致性

    请将分析结果以JSON格式返回，格式如下：
    {
      "overallQuality": number, // 评分，范围1-10
      "issues": [
        {
          "type": string, // 取值之一："ambiguity"（歧义）、"structure"（结构问题）、"contradiction"（矛盾）、"missing"（缺失）、"other"（其他）
          "severity": string, // 取值之一："error"（错误）、"warning"（警告）、"suggestion"（建议）
          "description": string, // 问题描述
          "recommendation": string // 改进建议
        }
      ],
      "improvedVersion": string // 修订后的提示内容
    }

    以下是需要分析的提示内容：

    """
    ${prompt}
    """

    请只返回JSON格式的输出，不要添加任何额外文字。
  `;

  const analysisResult = await model.complete(metaPrompt, { temperature: 0.1 });

  try {
    return JSON.parse(analysisResult);
  } catch (e) {
    return {
      error: "无法将LLM输出解析为JSON格式",
      rawOutput: analysisResult,
    };
  }
}
```

通过这种方式，我们让 LLM 生成越来越好的提示，从而产生越来越好的代码。

---

## Prompts Are Code   提示即代码

Prompt Engineering 正在变成一种严肃的开发学科，拥有**模式、工具和方法论**，就像任何其他软件开发领域一样。

- Few-shot 示例 ≈ 测试用例
- Chain-of-thought 推理 ≈ 强制展示工作过程
- Skeleton 提示 ≈ 模板控制
- Prompt 版本控制、测试、部署 ≈ 正规开发流程

**停止把你的 Prompt 当成临时字符串。**  
像写软件一样去**构建、测试、维护**你的 Prompt——你的 AI 应用也将变得像传统代码一样可靠。
