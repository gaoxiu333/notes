---
title: "我如何使用LLM辅助编写代码"
date: 2025-03-11
tags: 
  - type/guide
  - subject/ai
  - topic/coding
source: https://simonwillison.net/2025/Mar/11/using-llms-for-code/
author: Simon Willison
status: completed
---

# 我如何使用LLM辅助编写代码

在关于[使用大型语言模型辅助编写代码](https://simonwillison.net/tags/ai-assisted-programming/)的在线讨论中，不可避免地会有一些开发人员评论他们的经验令人失望。他们经常问自己哪里做错了 - 为什么有些人报告了如此出色的结果，而他们自己的实验却证明不足？

使用LLM编写代码是**困难的**和**违反直觉的**。需要付出巨大的努力才能弄清楚以这种方式使用它们的优势和劣势，而且几乎没有指导可以帮助人们弄清楚如何最好地应用它们。

如果有人告诉你使用LLM进行编码是_容易的_，那么他们（可能无意中）误导了你。他们很可能偶然发现了一些有效的模式，但这些模式并非对每个人都适用。

两年来，我一直在从LLM中获得出色的代码结果。这是我尝试将一些经验和直觉传授给你的尝试。

## 目录

- [设定合理的期望](#设定合理的期望)
- [考虑训练截止日期](#考虑训练截止日期)
- [上下文为王](#上下文为王)
- [向他们询问选项](#向他们询问选项)
- [告诉他们该怎么做](#告诉他们该怎么做)
- [你必须测试它写的东西！](#你必须测试它写的东西)
- [记住这是一场对话](#记住这是一场对话)
- [使用可以为你运行代码的工具](#使用可以为你运行代码的工具)
- [Vibe-coding是一种很好的学习方式](#vibe-coding是一种很好的学习方式)
- [使用Claude Code的详细示例](#使用-claude-code-的详细示例)
- [准备好让人类接管](#准备好让人类接管)
- [最大的优势是开发速度](#最大的优势是开发速度)
- [LLM扩大了现有专业知识](#llm扩大了现有专业知识)
- [回答有关代码库的问题](#回答有关代码库的问题)

## 设定合理的期望

忽略"AGI"的炒作 - LLM仍然是花哨的自动完成。他们所做的只是预测一系列token - 但事实证明，编写代码主要是在正确的顺序中将token串在一起，因此如果你将它们指向正确的方向，它们可能会_非常_有用。

如果你认为这项技术可以完美地实现你的项目，而无需你运用自己的任何技能，那么你很快就会失望。

相反，使用它们来_增强_你的能力。我目前最喜欢的思维模式是将它们视为一个过度自信的结对编程助手，他们可以快速查找东西，可以随时快速生成相关的示例，并且可以毫不抱怨地执行繁琐的任务。

**过度自信**很重要。他们绝对会犯错误 - 有时是微妙的，有时是巨大的。这些错误可能[非常不人道](https://simonwillison.net/2025/Mar/2/kellan-elliott-mccrea/) - 如果人类合作者幻想着一个不存在的库或方法，你将立即失去对他们的信任。不要陷入将LLM人格化的陷阱，并假设会使人类失去信誉的失败应该以同样的方式使机器失去信誉。

在使用LLM时，你经常会发现它们无法做到某些事情。记下这些 - 它们是有用的教训！它们也是未来存放起来的宝贵示例 - 一个强大的新模型的标志是，当它为以前的模型无法处理的任务生成可用的结果时。

## 考虑训练截止日期

任何模型的关键特征都是其**训练截止日期**。这是他们接受训练的数据停止收集的日期。对于OpenAI的模型，这通常是2023年10月。Anthropic和Gemini以及其他提供商可能有更近的日期。

这对于代码来说_极其_重要，因为它会影响他们熟悉的库。如果你使用的库自2023年10月以来发生了重大突破性更改，OpenAI模型将不会知道！

我从LLM中获得了足够的价值，我现在在选择库时会故意考虑这一点 - 我尝试坚持使用具有良好稳定性的库，并且这些库足够流行，以至于它们的许多示例都已进入训练数据。我喜欢应用[无聊技术](https://boringtechnology.club/)的原则 - 在你项目的独特卖点上进行创新，坚持使用经过试验和测试的解决方案来解决其他问题。

LLM仍然可以帮助你使用其训练数据之外存在的库，但你需要投入更多的工作 - 你需要将这些库应如何使用的最新示例作为提示的一部分提供给它们。

这使我们了解了在使用LLM时要理解的最重要的事情：

## 上下文为王

从LLM中获得良好结果的大部分技巧都归结为管理其上下文 - 即你当前对话的一部分文本。

此上下文不仅仅是你提供给它的提示：成功的LLM交互通常采用对话的形式，并且上下文包括你_和_LLM的每个消息，这些消息都存在于当前对话线程中。

当你开始新的对话时，你会将该上下文重置为零。了解这一点很重要，因为通常修复已停止有用的对话的方法是擦除石板并重新开始。

例如，某些LLM编码工具不仅仅是对话。例如，Claude Projects允许你使用相当大量的文本来预先填充上下文 - 包括最近[从GitHub直接导入代码](https://support.anthropic.com/en/articles/10167454-using-the-github-integration)的功能，我正在大量使用该功能。

像Cursor和VS Code Copilot这样的工具会自动包含来自你当前编辑器会话和文件布局的上下文，有时你可以使用[Cursor的@commands](https://docs.cursor.com/context/@-symbols/overview)之类的机制来提取其他文件或文档。

我主要直接使用[ChatGPT](https://chatgpt.com/)和[Claude](https://claude.ai/)网络或应用程序界面的原因之一是，它可以让我更轻松地了解上下文中到底有什么。对我隐藏该上下文的LLM工具_不太_有效。

你可以利用以前的回复也是上下文的一部分这一事实来发挥自己的优势。对于复杂的编码任务，请尝试首先让LLM编写一个更简单的版本，检查它是否有效，然后迭代构建到更复杂的实现。

我经常通过转储现有代码来启动新的聊天来为该上下文添加种子，然后与LLM合作以某种方式修改它。

我最喜欢的代码提示技术之一是放入几个与我想构建的东西相关的完整示例，然后提示LLM将它们用作新项目的灵感。当我[描述我的JavaScript OCR应用程序](https://simonwillison.net/2024/Mar/30/ocr-pdfs-images/)时，我详细介绍了这一点，该应用程序结合了Tesseract.js和PDF.js - 我过去曾使用过的两个库，并且我可以在提示中提供有效的示例。

## 向他们询问选项

我的大多数项目都始于一些开放性问题：我试图做的事情是否可行？我可以通过哪些潜在的方式来实现它？这些选项中哪个是_最好的_？

我将LLM用作此初始研究阶段的一部分。

我将使用诸如"Rust中HTTP库有哪些选项？包括使用示例"之类的提示 - 或者"JavaScript中有哪些有用的拖放库？为我构建一个演示每个库的工件"（对于Claude）。

训练截止日期与此相关，因为它意味着不会推荐较新的库。通常这没关系 - 我不想要最新的，我想要最稳定的，并且已经存在了足够长的时间来消除错误。

如果我要使用更新的东西，我将在LLM世界之外自己进行研究。

启动任何项目的最佳方法是使用原型来证明可以满足该项目的关键要求。我经常发现，在坐到笔记本电脑前几分钟内，或者有时甚至在手机上工作时，LLM就可以让我获得该工作原型。

## 告诉他们该怎么做

完成初始研究后，我戏剧性地改变了模式。对于生产代码，我对LLM的使用更加专制：我将其视为数字实习生，根据我的详细说明为我键入代码。

这是一个最近的例子：

> 编写一个使用asyncio httpx的Python函数，其签名为：
>
> ```
> async def download_db(url, max_size_bytes=5 * 1025 * 1025): -> pathlib.Path
> ```
>
> 给定一个URL，这将数据库下载到临时目录并返回其路径。但是，它会在流式传输回该数据开始时检查内容长度标头，如果超过限制，则会引发错误。下载完成后，它使用`sqlite3.connect(...)`，然后运行`PRAGMA quick_check`以确认SQLite数据有效 - 如果无效则引发错误。最后，如果内容长度标头对我们撒谎 - 如果它说2MB但我们下载了3MB - 我们会在注意到该问题后立即引发错误。

我可以自己编写这个函数，但这将花费我大部分时间来查找所有详细信息并使代码正常工作。Claude在[15秒内](https://gist.github.com/simonw/5aed8bd87016c77465c23e0dc4563ec9)将其淘汰。

我发现LLM对我在此处使用的函数签名反应非常好。我可以充当函数设计者，LLM完成构建主体的任务以满足我的规范。

我经常会接着说"现在使用pytest为我编写测试"。同样，我指定了我选择的技术 - 我希望LLM节省我必须输入已经存在于我脑海中的代码的时间。

如果你的反应是"当然，输入代码比输入它的英语指令更快"，我只能告诉你，对我来说真的不是这样了。代码需要正确。英语有很大的捷径、含糊不清和错别字的空间，如果你不记得名字，可以说"使用那个流行的HTTP库"之类的话。

优秀的编码LLM非常擅长填补空白。它们也比我懒惰得多 - 它们会记住捕获可能的异常，添加准确的文档字符串，并使用相关的类型注释来注释代码。

## 你必须测试它写的东西！

我[上周](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/#qa)对此进行了详细介绍：你绝对不能外包给机器的一件事是测试代码是否真的有效。

你作为软件开发人员的责任是交付可工作的系统。如果你没有看到它运行，它就不是一个可工作的系统。你需要投资于加强这些手动QA习惯。

这可能并不迷人，但无论是否涉及LLM，它一直是交付优秀代码的关键部分。

## 记住这是一场对话

如果我不喜欢LLM编写的内容，他们_永远_不会抱怨被告知要重构它！"将该重复代码分解为一个函数"、"使用字符串操作方法而不是正则表达式"，甚至"更好地编写它！" - LLM第一次生成的代码很少是最终实现，但它们可以为你重新键入数十次，而不会感到沮丧或厌烦。

偶尔我会从我的第一个提示中获得一个很棒的结果 - 随着我练习的次数增加，这种情况会更频繁地发生 - 但我希望至少需要几个后续步骤。

我经常想知道这是否是人们遗漏的关键技巧之一 - 一个糟糕的初始结果不是失败，而是推动模型朝着你真正想要的东西发展的起点。

## 使用可以为你运行代码的工具

现在，越来越多的LLM编码工具能够为你_运行该代码_。我对其中一些工具持谨慎态度，因为错误的命令可能会造成实际损害，因此我倾向于坚持在安全沙箱中运行代码的工具。我现在最喜欢的是：

- **ChatGPT Code Interpreter**，其中ChatGPT可以直接在OpenAI管理的Kubernetes沙箱VM中编写然后执行Python代码。这是完全安全的 - 它甚至无法建立出站网络连接，因此真正可能发生的是临时文件系统被破坏然后重置。

- **Claude Artifacts**，其中Claude可以为你构建一个完整的HTML+JavaScript+CSS Web应用程序，该应用程序显示在Claude界面中。此Web应用程序显示在_非常_锁定的iframe沙箱中，极大地限制了它可以执行的操作，但可以防止诸如意外泄露你的私有Claude数据之类的问题。

- **ChatGPT Canvas**是ChatGPT的一项较新功能，其功能与Claude Artifacts类似。我自己还没有对此进行足够的探索。

如果你愿意生活得更危险一点：

- **[Cursor](https://www.cursor.com/)**具有可以执行此操作的"代理"功能，**[Windsurf](https://codeium.com/windsurf)**以及越来越多的其他编辑器也是如此。我还没有花足够的时间来提出建议。

- **[Aider](https://aider.chat/)**是这些类型模式的主要开源实现，并且是[dogfooding](https://en.wikipedia.org/wiki/Eating_your_own_dog_food)的一个很好的例子 - Aider的最新版本已由Aider本身[编写了80%以上](https://aider.chat/HISTORY.html)。

- **[Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview)**是Anthropic进入该领域的新产品。我将很快提供有关使用该工具的详细说明。

这种在循环中运行代码的模式非常强大，以至于我选择用于编码的核心LLM工具主要基于它们是否可以安全地运行和迭代我的代码。

## Vibe-coding是一种很好的学习方式

Andrej Karpathy在一个多月前[创造了术语](https://simonwillison.net/2025/Feb/6/andrej-karpathy/)vibe-coding，并且它已经坚持了下来：

> 有一种新的编码方式，我称之为"vibe coding"，你完全沉浸在氛围中，拥抱指数，并忘记代码的存在。[...] 我要求做最愚蠢的事情，比如"将侧边栏上的填充减少一半"，因为我太懒了，找不到它。我总是"全部接受"，我不再阅读差异。当我收到错误消息时，我只是复制粘贴它们，通常可以解决问题。

Andrej建议这"对于一次性周末项目来说还不错"。这也是探索这些模型的功能以及真正有趣的方式。

学习LLM的最佳方法是使用它们。向他们抛出荒谬的想法并进行vibe-coding，直到他们几乎可以进行排序，这确实是一种有用的方法，可以加快你建立对什么有效和什么无效的直觉的速度。

自从Andrej给它命名之前，我就一直在进行vibe-coding！我的[simonw/tools](https://github.com/simonw/tools) GitHub存储库有77个HTML+JavaScript应用程序和6个Python应用程序，并且它们中的每一个都是通过提示LLM构建的。我从构建此集合中学到了_很多_，并且我以每周几个新原型的速度添加到它。

你可以直接在[tools.simonwillison.net](https://tools.simonwillison.net/)上试用我的大部分工具 - 这是该存储库的GitHub Pages发布版本。我在10月份的[本周我使用Claude Artifacts构建的所有内容](https://simonwillison.net/2024/Oct/21/claude-artifacts/)中写了更多关于其中一些工具的详细说明。

如果你想查看用于每个工具的聊天的记录，它几乎总是链接到该页面的提交历史记录中 - 或者访问新的[colophon页面](https://tools.simonwillison.net/colophon)以获取包含所有这些链接的索引。

## 使用Claude Code的详细示例

在撰写本文时，我想到了[tools.simonwillison.net/colophon](https://tools.simonwillison.net/colophon)页面 - 我想要一些我可以链接到的东西，以比GitHub更明显的方式显示我的每个工具的提交历史记录。

我决定以此为例来演示我的AI辅助编码过程。

对于这个，我使用了[Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview)，因为我希望它能够直接针对我笔记本电脑上现有的工具存储库运行Python代码。

在会话结束时运行`/cost`命令向我显示了以下内容：

```
> /cost
  ⎿  总成本：0.61美元
     总持续时间（API）：5分31.2秒
     总持续时间（墙）：17分18.7秒
```

从开始到结束，最初的项目花费了我17分多一点的时间，并花费了我61美分的API调用费用给Anthropic。

我使用了专制的流程，我告诉模型我想要构建什么。这是我的提示序列（[此处提供完整记录](https://gist.github.com/simonw/323e1b00ee4f8453c7834a7560eeafc1)）。

我首先要求提供一个初始脚本来收集新页面所需的数据：

> 此目录中的几乎所有HTML文件都是使用Claude提示创建的，并且这些提示的详细信息链接在提交消息中。构建一个Python脚本，该脚本依次检查每个HTML文件的提交历史记录，并将这些提交消息中的任何URL提取到列表中。然后，它应该输出一个具有以下结构的JSON文件：{"pages": {"name-of-file.html": ["url"], {"name-of-file-2.html": ["url1", "url2"], ... - 正如你所看到的，某些文件可能在其提交历史记录中具有多个URL。该脚本应称为gather_links.py，并且应保存一个名为gathered_links.json的JSON文件

我真的没有认真考虑这第一个提示 - 这更像是当我在考虑初始问题时输入到机器人中的意识流。

我检查了初始结果并发现了一些问题：

> 看起来它只是获得了URL的开头，它应该获得完整的URL，这些URL可能是指向不同网站的 - 因此只需获取任何以https://开头并以空格或提交消息结尾的内容

然后我改变了主意 - 我也想要那些完整的提交消息：

> 更新脚本 - 我想捕获完整的提交消息_和_URL - 新格式应为{"pages": {"aria-live-regions.html": {"commits": ["hash": hash, "message": message, "date": iso formatted date], "urls": [list of URLs like before]

## 准备好让人类接管

LLM很擅长简单和中等复杂度的编码任务，但它们确实有自己的局限性。更复杂的项目通常会达到一个点，需要人类的专业知识来接管。

了解何时依赖LLM和何时应该由你亲自完成工作是AI辅助编码的关键技能。当你的任务涉及复杂的系统设计、非常特定的业务逻辑、安全关键型功能或需要深度领域知识时，这可能是该让人类接管的时候了。

我通常会将LLM视为编码合作伙伴，而不是编码替代者。它们可以帮助我加快开发速度，但最终的责任和最终决策权仍然在我这里。

## 最大的优势是开发速度

使用LLM进行编码工作的最大好处在于开发速度的惊人提升。我可以在几分钟或几小时内构建以前可能需要几天才能完成的项目原型。

这种速度优势是转换性的 - 它不仅让我更有效率，而且改变了我考虑可能的方式。我现在更愿意尝试新想法，因为探索它们的成本如此之低。如果一个想法不起作用，我可以快速迭代或尝试完全不同的方法，而不会感到我浪费了大量时间。

LLM不仅帮助我更快地编写代码，而且可以减少搜索文档、查找示例或记住API细节的时间。它们本质上是知识库，可以在我需要时立即访问。

## LLM扩大了现有专业知识

值得注意的是，LLM往往会扩大而不是替代你的现有专业知识。如果你已经是某个领域的专家，LLM可以大大提高你的生产力。相比之下，如果你在某个领域是新手，它们可能会提供帮助，但不太可能使你变成专家。

这也意味着，随着你开始使用LLM进行编码，你的编程技能不会萎缩 - 相反，你会发展出一组补充技能，使你能够更有效地使用这些工具。

## 回答有关代码库的问题

作为结束，我想强调LLM在回答有关代码库的问题方面的巨大价值。

当与大型、复杂的代码库合作时，可能很难理解特定组件如何工作或某些功能是如何实现的。LLM，特别是那些可以访问你代码库的LLM，可以成为无价的解释者。

你可以询问诸如"这个类的主要目的是什么？"、"这个函数的参数代表什么？"或"这段代码是如何处理错误情况的？"之类的问题。在很多情况下，它们可以提供比手动梳理代码更快、更简单的解释。

这种能力对于团队协作、熟悉新项目或理解遗留代码尤其有价值。它们就像是在需要时随时可用的同事，可以帮助你理解你不熟悉的代码部分。 